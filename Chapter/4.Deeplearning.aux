\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {第4章}深層学習}{44}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\jsc@mpt }}
\@writefile{lot}{\addvspace {10\jsc@mpt }}
\newlabel{sec:Deeplearning}{{4}{44}{深層学習}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}ニューラルネットワーク}{44}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}パーセプトロン（単層ニューラルネットワーク）}{44}{subsection.4.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces パーセプトロン\relax }}{44}{figure.caption.49}\protected@file@percent }
\newlabel{perceptron}{{4.1}{44}{パーセプトロン\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}多層パーセプトロン（多層ニューラルネットワーク）}{45}{subsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces 多層パーセプトロン（ニューラルネットワーク）\relax }}{45}{figure.caption.50}\protected@file@percent }
\newlabel{mlp}{{4.2}{45}{多層パーセプトロン（ニューラルネットワーク）\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsubsection}{活性化関数}{46}{section*.51}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces 活性化関数のグラフ。Forwardは順方向、backwardは逆方向 (後に誤差逆伝播法で説明) の際の演算を表す。\relax }}{47}{figure.caption.52}\protected@file@percent }
\newlabel{hitmap}{{4.3}{47}{活性化関数のグラフ。Forwardは順方向、backwardは逆方向 (後に誤差逆伝播法で説明) の際の演算を表す。\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {subsubsection}{出力層の設計}{47}{section*.53}\protected@file@percent }
\newlabel{softmax}{{4.12}{47}{出力層の設計}{equation.4.1.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{損失関数}{47}{section*.54}\protected@file@percent }
\newlabel{mse}{{4.13}{48}{損失関数}{equation.4.1.13}{}}
\newlabel{cee}{{4.14}{48}{損失関数}{equation.4.1.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{誤差逆伝播法}{48}{section*.55}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{前処理}{48}{section*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{ミニバッチ処理}{49}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{最適化アルゴリズム}{49}{section*.58}\protected@file@percent }
\newlabel{gd}{{4.18}{49}{最適化アルゴリズム}{equation.4.1.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{過学習}{50}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}ディープニューラルネットワーク}{51}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}グラフニューラルネットワーク}{51}{section.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces ディープニューラルネットワーク\relax }}{52}{figure.caption.60}\protected@file@percent }
\newlabel{dnn}{{4.4}{52}{ディープニューラルネットワーク\relax }{figure.caption.60}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}メッセージパッシング}{52}{subsection.4.2.1}\protected@file@percent }
\newlabel{gnnm}{{4.25}{53}{メッセージパッシング}{equation.4.2.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces  (左) 4つのノードを持つ全結合グラフニューラルネットワーク。$h_i$はノード表現を表す。 (右) メッセージパッシングの処理。\relax }}{53}{figure.caption.61}\protected@file@percent }
\newlabel{messagepass}{{4.5}{53}{(左) 4つのノードを持つ全結合グラフニューラルネットワーク。$h_i$はノード表現を表す。 (右) メッセージパッシングの処理。\relax }{figure.caption.61}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Graph Convolution Network (GCN)}{53}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Spectral Graph Convolution}{53}{section*.62}\protected@file@percent }
\citation{graphsage}
\@writefile{toc}{\contentsline {subsubsection}{Spatial Graph Convolution}{54}{section*.63}\protected@file@percent }
\citation{gat}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces GraphSAGEにおける処理(1. サンプリング, 2. 隣接からの集約, 3. 学習結果による推論)\relax }}{55}{figure.caption.64}\protected@file@percent }
\newlabel{sage}{{4.6}{55}{GraphSAGEにおける処理(1. サンプリング, 2. 隣接からの集約, 3. 学習結果による推論)\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Graph Attention Network (GAT)}{55}{subsection.4.2.3}\protected@file@percent }
\newlabel{GATexplain}{{4.2.3}{55}{Graph Attention Network (GAT)}{subsection.4.2.3}{}}
\newlabel{gatattention}{{4.35}{55}{Graph Attention Network (GAT)}{equation.4.2.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces  (左) 重みベクトル$\mathbf   {a}$を用いたAttention処理。 (右) 1つのノード$\mathbf   {h}_1$に対する隣接ノード$\mathbf   {h}_{\neq  1}$のAttentionと、ノード特徴量の更新$\mathbf   {h'}_1$\relax }}{56}{figure.caption.65}\protected@file@percent }
\@setckpt{Chapter/4.Deeplearning}{
\setcounter{page}{57}
\setcounter{equation}{35}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{2}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{7}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{0}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{4}
\setcounter{section@level}{2}
}
