\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {第4章}深層学習}{41}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\jsc@mpt }}
\@writefile{lot}{\addvspace {10\jsc@mpt }}
\newlabel{sec:Deeplearning}{{4}{41}{深層学習}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}ニューラルネットワーク}{41}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}パーセプトロン（単層ニューラルネットワーク）}{41}{subsection.4.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces パーセプトロン\relax }}{41}{figure.caption.39}\protected@file@percent }
\newlabel{perceptron}{{4.1}{41}{パーセプトロン\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}多層パーセプトロン（多層ニューラルネットワーク）}{42}{subsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces 多層パーセプトロン（ニューラルネットワーク）\relax }}{42}{figure.caption.40}\protected@file@percent }
\newlabel{mlp}{{4.2}{42}{多層パーセプトロン（ニューラルネットワーク）\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{活性化関数}{43}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{出力層の設計}{43}{section*.42}\protected@file@percent }
\newlabel{softmax}{{4.11}{44}{出力層の設計}{equation.4.1.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{損失関数}{44}{section*.43}\protected@file@percent }
\newlabel{mse}{{4.12}{44}{損失関数}{equation.4.1.12}{}}
\newlabel{cee}{{4.13}{44}{損失関数}{equation.4.1.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{誤差逆伝播法}{44}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{前処理}{45}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{ミニバッチ処理}{45}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{最適化アルゴリズム}{45}{section*.47}\protected@file@percent }
\newlabel{gd}{{4.17}{46}{最適化アルゴリズム}{equation.4.1.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}ディープニューラルネットワーク}{46}{subsection.4.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces ディープニューラルネットワーク\relax }}{47}{figure.caption.48}\protected@file@percent }
\newlabel{dnn}{{4.3}{47}{ディープニューラルネットワーク\relax }{figure.caption.48}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}グラフニューラルネットワーク}{47}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}メッセージパッシング}{48}{subsection.4.2.1}\protected@file@percent }
\newlabel{gnnm}{{4.23}{48}{メッセージパッシング}{equation.4.2.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces  (左) 4つのノードを持つ全結合グラフニューラルネットワーク。$h_i$はノード表現を表す。 (右) メッセージパッシングの処理。\relax }}{48}{figure.caption.49}\protected@file@percent }
\newlabel{messagepass}{{4.4}{48}{(左) 4つのノードを持つ全結合グラフニューラルネットワーク。$h_i$はノード表現を表す。 (右) メッセージパッシングの処理。\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Graph Convolution Network (GCN)}{48}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Spectral Graph Convolution}{48}{section*.50}\protected@file@percent }
\citation{graphsage}
\@writefile{toc}{\contentsline {subsubsection}{Spatial Graph Convolution}{49}{section*.51}\protected@file@percent }
\citation{gat}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces GraphSAGEにおける処理(1. サンプリング, 2. 隣接からの集約, 3. 学習結果による推論)\relax }}{50}{figure.caption.52}\protected@file@percent }
\newlabel{sage}{{4.5}{50}{GraphSAGEにおける処理(1. サンプリング, 2. 隣接からの集約, 3. 学習結果による推論)\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Graph Attention Network (GAT)}{50}{subsection.4.2.3}\protected@file@percent }
\newlabel{GATexplain}{{4.2.3}{50}{Graph Attention Network (GAT)}{subsection.4.2.3}{}}
\newlabel{gatattention}{{4.33}{51}{Graph Attention Network (GAT)}{equation.4.2.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces  (左) 重みベクトル$\mathbf   {a}$を用いたAttention処理。 (右) 1つのノード$\mathbf   {h}_1$に対する隣接ノード$\mathbf   {h}_{\neq  1}$のAttentionと、ノード特徴量の更新$\mathbf   {h'}_1$\relax }}{51}{figure.caption.53}\protected@file@percent }
\@setckpt{Chapter/4.Deeplearning}{
\setcounter{page}{52}
\setcounter{equation}{33}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{2}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{0}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{74}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{4}
\setcounter{section@level}{2}
}
